import streamlit as st
from services.agent import get_agent, get_available_models

def render_investigation_tab(df_faturas):
    # --- 1. CONFIGURAÃ‡ÃƒO (API Key e Modelo) ---
    st.markdown("### ğŸ•µï¸â€â™‚ï¸ ConfiguraÃ§Ã£o da InvestigaÃ§Ã£o")

    if "api_key" not in st.session_state: st.session_state.api_key = ""
    if "selected_model" not in st.session_state: st.session_state.selected_model = "gemini-1.5-flash"
    if "messages" not in st.session_state: st.session_state.messages = []

    config_expanded = not bool(st.session_state.api_key)

    with st.expander("ğŸ”‘ Credenciais e Modelo do Agente", expanded=config_expanded):
        col_key, col_model = st.columns([2, 1])
        with col_key:
            input_key = st.text_input("Google API Key", type="password", value=st.session_state.api_key)
            if input_key: st.session_state.api_key = input_key
        with col_model:
            if st.session_state.api_key:
                try:
                    modelos = get_available_models(st.session_state.api_key)
                    st.session_state.selected_model = st.selectbox("Agente", modelos, index=0)
                except:
                    st.session_state.selected_model = st.selectbox("Modelo", ["gemini-1.5-flash"])
            else:
                st.selectbox("Modelo", ["Insira a chave primeiro"], disabled=True)

    # --- 2. CONTEXTO ---
    with st.expander("ğŸ“š O que o Detetive sabe? (Amostra de dados)"):
        st.dataframe(df_faturas.head(3), width="stretch", hide_index=True)

    st.divider()

    # --- 3. CHAT ---
    if not st.session_state.api_key:
        st.info("ğŸ”’ Insira sua **Google API Key** acima para comeÃ§ar.")
        return

    col_title, col_actions = st.columns([2, 1])
    with col_title: st.markdown(f"#### ğŸ’¬ Detetive: `{st.session_state.selected_model}`")
    with col_actions:
        c1, c2 = st.columns(2)
        if c1.button("ğŸ—‘ï¸ Limpar", width="stretch"):
            st.session_state.messages = []
            st.rerun()

        chat_text = "\n\n".join([f"**{m['role'].upper()}**: {m['content']}" for m in st.session_state.messages])
        c2.download_button("ğŸ’¾ Salvar", data=chat_text, file_name="investigacao.md", width="stretch")

    # DefiniÃ§Ã£o de Ã­cones
    ai_avatar = "ğŸ•µï¸â€â™‚ï¸"
    user_avatar = "ğŸ‘¤"

    # Container principal do chat para manter a ordem visual correta
    chat_container = st.container()

    # HistÃ³rico
    with chat_container:
        for msg in st.session_state.messages:
            avatar = user_avatar if msg["role"] == "user" else ai_avatar
            with st.chat_message(msg["role"], avatar=avatar):
                st.markdown(msg["content"])

    # Mensagem de boas-vindas (Placeholder para ser removido ao iniciar)
    welcome_ph = st.empty()
    if not st.session_state.messages:
        with welcome_ph:
            st.markdown(
                """
                <div style='text-align: center; color: #888; margin-top: 40px; margin-bottom: 40px;'>
                    <h4>ğŸ‘‹ OlÃ¡! Sou seu Detetive Financeiro.</h4>
                    <p>Estou pronto para analisar suas faturas. FaÃ§a uma pergunta para comeÃ§ar a investigaÃ§Ã£o!</p>
                </div>
                """,
                unsafe_allow_html=True
            )

    if prompt := st.chat_input("Pergunte sobre seus gastos..."):
        welcome_ph.empty() # Limpa a mensagem de boas-vindas imediatamente
        st.session_state.messages.append({"role": "user", "content": prompt})

        with chat_container:
            with st.chat_message("user", avatar=user_avatar):
                st.markdown(prompt)

            with st.chat_message("assistant", avatar=ai_avatar):
                with st.spinner("ğŸ” Analisando evidÃªncias..."):
                    try:
                        agent = get_agent(st.session_state.selected_model, st.session_state.api_key)

                        # ConstrÃ³i prompt com contexto das Ãºltimas mensagens para manter a memÃ³ria da conversa
                        history = st.session_state.messages[:-1][-6:] # Pega os Ãºltimos 3 turnos (excluindo a pergunta atual)
                        if history:
                            context_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in history])
                            final_prompt = (
                                f"HistÃ³rico da conversa:\n{context_str}\n\n"
                                f"Pergunta atual: {prompt}\n"
                                f"Responda Ã  pergunta atual considerando o contexto acima se necessÃ¡rio."
                            )
                        else:
                            final_prompt = prompt

                        resp_box = st.empty()
                        full_resp = ""
                        for chunk in agent.run(final_prompt, stream=True):
                            if chunk.content:
                                full_resp += chunk.content
                                resp_box.markdown(full_resp + "â–Œ")
                        resp_box.markdown(full_resp)
                        st.session_state.messages.append({"role": "assistant", "content": full_resp})
                    except Exception as e:
                        st.error(f"âŒ Ocorreu um erro na investigaÃ§Ã£o: {e}")
